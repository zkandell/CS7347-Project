{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn for various machine learning algorithms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# CountVectorizer for converting text data into a matrix of token counts\n",
    "# Not the only way to do this, but a simple and common way\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Pandas for working with dataframes (including the one already created by the data processing notebook)\n",
    "import pandas as pd\n",
    "# Numpy for working with arrays\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Book  \\\n",
      "0                              To Kill a Mockingbird   \n",
      "1  Harry Potter and the Philosopher’s Stone (Harr...   \n",
      "2                                Pride and Prejudice   \n",
      "3                                  The Little Prince   \n",
      "4                                               1984   \n",
      "\n",
      "                                         Description  \\\n",
      "0  The unforgettable novel of a childhood in a sl...   \n",
      "1  Harry Potter thinks he is an ordinary boy - un...   \n",
      "2  Since its immediate success in 1813, Pride and...   \n",
      "3  A pilot stranded in the desert awakes one morn...   \n",
      "4  The new novel by George Orwell is the major wo...   \n",
      "\n",
      "                     Author  Fantasy  Adult  Romance  Young Adult  Historical  \\\n",
      "0                Harper Lee        0      1        0            1           1   \n",
      "1              J.K. Rowling        1      1        0            1           0   \n",
      "2               Jane Austen        0      0        1            0           1   \n",
      "3  Antoine de Saint-Exupéry        1      1        0            1           0   \n",
      "4             George Orwell        0      0        0            0           0   \n",
      "\n",
      "   Historical Fiction  Mystery  ...  Suspense  Horror  Paranormal  Magic  \\\n",
      "0                   1        0  ...         0       0           0      0   \n",
      "1                   0        0  ...         0       0           0      1   \n",
      "2                   1        0  ...         0       0           0      0   \n",
      "3                   0        0  ...         0       0           0      0   \n",
      "4                   0        0  ...         0       0           0      0   \n",
      "\n",
      "   Science Fiction Fantasy  Humor  Middle Grade  Literary Fiction  Drama  \\\n",
      "0                        0      0             0                 0      0   \n",
      "1                        0      0             1                 0      0   \n",
      "2                        0      0             0                 0      0   \n",
      "3                        0      0             0                 0      0   \n",
      "4                        0      0             0                 0      0   \n",
      "\n",
      "   American  \n",
      "0         0  \n",
      "1         0  \n",
      "2         0  \n",
      "3         0  \n",
      "4         0  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "(6079, 28)\n"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data = pd.read_csv('Datasets/goodreads_data_onehot_genres.csv')\n",
    "\n",
    "# Print the first few rows of the data\n",
    "print(data.head())\n",
    "# Print the shape of the data\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Author', 'Fantasy', 'Adult', 'Romance', 'Young Adult', 'Historical',\n",
      "       'Historical Fiction', 'Mystery', 'Contemporary', 'Thriller', 'Science',\n",
      "       'Science Fiction', 'Adventure', 'Mystery Thriller', 'Crime',\n",
      "       'Childrens', 'Suspense', 'Horror', 'Paranormal', 'Magic',\n",
      "       'Science Fiction Fantasy', 'Humor', 'Middle Grade', 'Literary Fiction',\n",
      "       'Drama', 'American'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the list of genres from the columns of the dataframe\n",
    "genres = data.columns[2:]\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['Description'], data[genres], test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a vectorizer to convert the text data into a matrix of token counts\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Fit the vectorizer to the training data\n",
    "vectorizer.fit(X_train)\n",
    "\n",
    "# Transform the training and testing data\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train a Naive Bayes classifier for a given genre\n",
    "def train_genre_classifier(genre):\n",
    "    # Create a Naive Bayes classifier\n",
    "    classifier = MultinomialNB()\n",
    "    # Train the classifier on the training data\n",
    "    classifier.fit(X_train, y_train[genre])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Fantasy', 'Adult', 'Romance', 'Young Adult', 'Historical',\n",
      "       'Historical Fiction', 'Mystery', 'Contemporary', 'Thriller', 'Science',\n",
      "       'Science Fiction', 'Adventure', 'Mystery Thriller', 'Crime',\n",
      "       'Childrens', 'Suspense', 'Horror', 'Paranormal', 'Magic',\n",
      "       'Science Fiction Fantasy', 'Humor', 'Middle Grade', 'Literary Fiction',\n",
      "       'Drama', 'American'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Get the list of genres from the columns of the dataframe\n",
    "genres = data.columns[3:]\n",
    "print(genres)\n",
    "\n",
    "# Create a dictionary to store the classifiers for each genre\n",
    "classifiers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training classifier for Fantasy\n",
      "Done training classifier for Fantasy\n",
      "Training classifier for Adult\n",
      "Done training classifier for Adult\n",
      "Training classifier for Romance\n",
      "Done training classifier for Romance\n",
      "Training classifier for Young Adult\n",
      "Done training classifier for Young Adult\n",
      "Training classifier for Historical\n",
      "Done training classifier for Historical\n",
      "Training classifier for Historical Fiction\n",
      "Done training classifier for Historical Fiction\n",
      "Training classifier for Mystery\n",
      "Done training classifier for Mystery\n",
      "Training classifier for Contemporary\n",
      "Done training classifier for Contemporary\n",
      "Training classifier for Thriller\n",
      "Done training classifier for Thriller\n",
      "Training classifier for Science\n",
      "Done training classifier for Science\n",
      "Training classifier for Science Fiction\n",
      "Done training classifier for Science Fiction\n",
      "Training classifier for Adventure\n",
      "Done training classifier for Adventure\n",
      "Training classifier for Mystery Thriller\n",
      "Done training classifier for Mystery Thriller\n",
      "Training classifier for Crime\n",
      "Done training classifier for Crime\n",
      "Training classifier for Childrens\n",
      "Done training classifier for Childrens\n",
      "Training classifier for Suspense\n",
      "Done training classifier for Suspense\n",
      "Training classifier for Horror\n",
      "Done training classifier for Horror\n",
      "Training classifier for Paranormal\n",
      "Done training classifier for Paranormal\n",
      "Training classifier for Magic\n",
      "Done training classifier for Magic\n",
      "Training classifier for Science Fiction Fantasy\n",
      "Done training classifier for Science Fiction Fantasy\n",
      "Training classifier for Humor\n",
      "Done training classifier for Humor\n",
      "Training classifier for Middle Grade\n",
      "Done training classifier for Middle Grade\n",
      "Training classifier for Literary Fiction\n",
      "Done training classifier for Literary Fiction\n",
      "Training classifier for Drama\n",
      "Done training classifier for Drama\n",
      "Training classifier for American\n",
      "Done training classifier for American\n"
     ]
    }
   ],
   "source": [
    "# Train a classifier for each genre\n",
    "# Check if the classifier is already trained\n",
    "for genre in genres:\n",
    "    if genre not in classifiers:\n",
    "        print('Training classifier for', genre)\n",
    "        classifiers[genre] = train_genre_classifier(genre)\n",
    "        print('Done training classifier for', genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate the accurace, precision, recall, and F1 score of a classifier for a given genre\n",
    "def evaluate_classifier(classifier, genre):\n",
    "    # Get the predictions of the classifier\n",
    "    predictions = classifier.predict(X_test)\n",
    "    # Calculate the accuracy of the classifier\n",
    "    accuracy = classifier.score(X_test, y_test[genre])\n",
    "    # Calculate the precision, recall, and F1 score of the classifier\n",
    "    true_positives = (predictions == 1) & (y_test[genre] == 1)\n",
    "    false_positives = (predictions == 1) & (y_test[genre] == 0)\n",
    "    false_negatives = (predictions == 0) & (y_test[genre] == 1)\n",
    "    precision = true_positives.sum() / (true_positives.sum() + false_positives.sum())\n",
    "    recall = true_positives.sum() / (true_positives.sum() + false_negatives.sum())\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    # Create a dictionary to store the evaluation metrics\n",
    "    evaluation = {\n",
    "        'accuracy': accuracy,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'f1': f1\n",
    "    }\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating classifier for Fantasy\n",
      "Done evaluating classifier for Fantasy\n",
      "Evaluating classifier for Adult\n",
      "Done evaluating classifier for Adult\n",
      "Evaluating classifier for Romance\n",
      "Done evaluating classifier for Romance\n",
      "Evaluating classifier for Young Adult\n",
      "Done evaluating classifier for Young Adult\n",
      "Evaluating classifier for Historical\n",
      "Done evaluating classifier for Historical\n",
      "Evaluating classifier for Historical Fiction\n",
      "Done evaluating classifier for Historical Fiction\n",
      "Evaluating classifier for Mystery\n",
      "Done evaluating classifier for Mystery\n",
      "Evaluating classifier for Contemporary\n",
      "Done evaluating classifier for Contemporary\n",
      "Evaluating classifier for Thriller\n",
      "Done evaluating classifier for Thriller\n",
      "Evaluating classifier for Science\n",
      "Done evaluating classifier for Science\n",
      "Evaluating classifier for Science Fiction\n",
      "Done evaluating classifier for Science Fiction\n",
      "Evaluating classifier for Adventure\n",
      "Done evaluating classifier for Adventure\n",
      "Evaluating classifier for Mystery Thriller\n",
      "Done evaluating classifier for Mystery Thriller\n",
      "Evaluating classifier for Crime\n",
      "Done evaluating classifier for Crime\n",
      "Evaluating classifier for Childrens\n",
      "Done evaluating classifier for Childrens\n",
      "Evaluating classifier for Suspense\n",
      "Done evaluating classifier for Suspense\n",
      "Evaluating classifier for Horror\n",
      "Done evaluating classifier for Horror\n",
      "Evaluating classifier for Paranormal\n",
      "Done evaluating classifier for Paranormal\n",
      "Evaluating classifier for Magic\n",
      "Done evaluating classifier for Magic\n",
      "Evaluating classifier for Science Fiction Fantasy\n",
      "Done evaluating classifier for Science Fiction Fantasy\n",
      "Evaluating classifier for Humor\n",
      "Done evaluating classifier for Humor\n",
      "Evaluating classifier for Middle Grade\n",
      "Done evaluating classifier for Middle Grade\n",
      "Evaluating classifier for Literary Fiction\n",
      "Done evaluating classifier for Literary Fiction\n",
      "Evaluating classifier for Drama\n",
      "Done evaluating classifier for Drama\n",
      "Evaluating classifier for American\n",
      "Done evaluating classifier for American\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the evaluation metrics for each genre\n",
    "evaluations = {}\n",
    "for genre in genres:\n",
    "    print('Evaluating classifier for', genre)\n",
    "    evaluations[genre] = evaluate_classifier(classifiers[genre], genre)\n",
    "    print('Done evaluating classifier for', genre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fantasy\n",
      "{'accuracy': 0.8667763157894737, 'precision': 0.8259587020648967, 'recall': 0.7310704960835509, 'f1': 0.7756232686980609}\n",
      "Adult\n",
      "{'accuracy': 0.7672697368421053, 'precision': 0.6794055201698513, 'recall': 0.7079646017699115, 'f1': 0.6933911159263271}\n",
      "Romance\n",
      "{'accuracy': 0.8379934210526315, 'precision': 0.7262773722627737, 'recall': 0.6199376947040498, 'f1': 0.6689075630252099}\n",
      "Young Adult\n",
      "{'accuracy': 0.834703947368421, 'precision': 0.7295081967213115, 'recall': 0.5686900958466453, 'f1': 0.6391382405745063}\n",
      "Historical\n",
      "{'accuracy': 0.8338815789473685, 'precision': 0.7280701754385965, 'recall': 0.5424836601307189, 'f1': 0.6217228464419475}\n",
      "Historical Fiction\n",
      "{'accuracy': 0.8379934210526315, 'precision': 0.7297297297297297, 'recall': 0.5418060200668896, 'f1': 0.6218809980806141}\n",
      "Mystery\n",
      "{'accuracy': 0.8692434210526315, 'precision': 0.8658536585365854, 'recall': 0.5089605734767025, 'f1': 0.6410835214446953}\n",
      "Contemporary\n",
      "{'accuracy': 0.8289473684210527, 'precision': 0.6729559748427673, 'recall': 0.4068441064638783, 'f1': 0.5071090047393365}\n",
      "Thriller\n",
      "{'accuracy': 0.8799342105263158, 'precision': 0.9047619047619048, 'recall': 0.41125541125541126, 'f1': 0.5654761904761905}\n",
      "Science\n",
      "{'accuracy': 0.8930921052631579, 'precision': 0.8548387096774194, 'recall': 0.3045977011494253, 'f1': 0.4491525423728813}\n",
      "Science Fiction\n",
      "{'accuracy': 0.8930921052631579, 'precision': 0.8548387096774194, 'recall': 0.3045977011494253, 'f1': 0.4491525423728813}\n",
      "Adventure\n",
      "{'accuracy': 0.8930921052631579, 'precision': 0.7777777777777778, 'recall': 0.1, 'f1': 0.17721518987341772}\n",
      "Mystery Thriller\n",
      "{'accuracy': 0.9037828947368421, 'precision': 0.7777777777777778, 'recall': 0.20437956204379562, 'f1': 0.3236994219653179}\n",
      "Crime\n",
      "{'accuracy': 0.9078947368421053, 'precision': 0.7317073170731707, 'recall': 0.22900763358778625, 'f1': 0.3488372093023256}\n",
      "Childrens\n",
      "{'accuracy': 0.9013157894736842, 'precision': 0.47368421052631576, 'recall': 0.15254237288135594, 'f1': 0.23076923076923078}\n",
      "Suspense\n",
      "{'accuracy': 0.9235197368421053, 'precision': 0.8235294117647058, 'recall': 0.1346153846153846, 'f1': 0.23140495867768596}\n",
      "Horror\n",
      "{'accuracy': 0.8939144736842105, 'precision': 0.08108108108108109, 'recall': 0.030612244897959183, 'f1': 0.04444444444444444}\n",
      "Paranormal\n",
      "{'accuracy': 0.9300986842105263, 'precision': 0.55, 'recall': 0.12643678160919541, 'f1': 0.20560747663551404}\n",
      "Magic\n",
      "{'accuracy': 0.9185855263157895, 'precision': 0.23076923076923078, 'recall': 0.03260869565217391, 'f1': 0.05714285714285715}\n",
      "Science Fiction Fantasy\n",
      "{'accuracy': 0.9350328947368421, 'precision': 0.3157894736842105, 'recall': 0.08333333333333333, 'f1': 0.13186813186813187}\n",
      "Humor\n",
      "{'accuracy': 0.9194078947368421, 'precision': 0.08333333333333333, 'recall': 0.02564102564102564, 'f1': 0.039215686274509796}\n",
      "Middle Grade\n",
      "{'accuracy': 0.9226973684210527, 'precision': 0.05, 'recall': 0.013157894736842105, 'f1': 0.020833333333333332}\n",
      "Literary Fiction\n",
      "{'accuracy': 0.9070723684210527, 'precision': 0.06060606060606061, 'recall': 0.023809523809523808, 'f1': 0.034188034188034185}\n",
      "Drama\n",
      "{'accuracy': 0.912828947368421, 'precision': 0.2682926829268293, 'recall': 0.12643678160919541, 'f1': 0.171875}\n",
      "American\n",
      "{'accuracy': 0.9185855263157895, 'precision': 0.10256410256410256, 'recall': 0.058823529411764705, 'f1': 0.07476635514018691}\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation metrics for each genre\n",
    "for genre in genres:\n",
    "    print(genre)\n",
    "    print(evaluations[genre])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The cosine similarity function\n",
    "def cosine_similarity(v1, v2):\n",
    "    # Convert the vectors to numpy arrays\n",
    "    v1 = np.array(v1)\n",
    "    v2 = np.array(v2)\n",
    "    # Calculate the dot product of the two vectors\n",
    "    dot_product = np.dot(v1, v2)\n",
    "    norm_v1 = np.linalg.norm(v1)\n",
    "    norm_v2 = np.linalg.norm(v2)\n",
    "    return dot_product / (norm_v1 * norm_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Book  \\\n",
      "0                              To Kill a Mockingbird   \n",
      "1  Harry Potter and the Philosopher’s Stone (Harr...   \n",
      "2                                Pride and Prejudice   \n",
      "3                                               1984   \n",
      "4                                   The Great Gatsby   \n",
      "\n",
      "                                             Similar  \\\n",
      "0                                  Go Set a Watchman   \n",
      "1  Harry Potter and the Order of the Phoenix (Har...   \n",
      "2                              Sense and Sensibility   \n",
      "3                                 Animal Farm / 1984   \n",
      "4                The Curious Case of Benjamin Button   \n",
      "\n",
      "                                          Dissimilar  \\\n",
      "0              The Complete Poems of Emily Dickinson   \n",
      "1                                        Strip Tease   \n",
      "2  Homeland (Forgotten Realms: The Dark Elf Trilo...   \n",
      "3                                   Everything Flows   \n",
      "4                           Ojo por ojo (Talion, #1)   \n",
      "\n",
      "                                    Book Description  \\\n",
      "0  The unforgettable novel of a childhood in a sl...   \n",
      "1  Harry Potter thinks he is an ordinary boy - un...   \n",
      "2  Since its immediate success in 1813, Pride and...   \n",
      "3  The new novel by George Orwell is the major wo...   \n",
      "4  Alternate Cover Edition ISBN: 0743273567 (ISBN...   \n",
      "\n",
      "                                 Similar Description  \\\n",
      "0  From Harper Lee comes a landmark new novel set...   \n",
      "1  'You are sharing the Dark Lord's thoughts and ...   \n",
      "2  Alternate cover edition of ISBN 9780141439662'...   \n",
      "3  This edition features George Orwell’s best-kno...   \n",
      "4  Today, F. Scott Fitzgerald is known for his no...   \n",
      "\n",
      "                              Dissimilar Description  \n",
      "0  THE ONLY ONE-VOLUME EDITION CONTAINING ALL 1,7...  \n",
      "1  No matter what you heard or thought about the ...  \n",
      "2  Drow ranger Drizzt Do'Urden, first introduced ...  \n",
      "3  'Everything Flows is as important a novel as a...  \n",
      "4  \\n\"NUEVO TWIST EN EXTRAÑOS EN UN TREN\" - THE S...  \n"
     ]
    }
   ],
   "source": [
    "# Load the recommendation dataset\n",
    "recommendations = pd.read_csv('Datasets/goodreads_recommendations.csv')\n",
    "\n",
    "# Print the first few rows of the recommendations\n",
    "print(recommendations.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.6693803215528125e-18, 2.1144844006661158e-11, 5.853368626857321e-21, 8.965822319073162e-17, 0.9999999983517682, 0.999999994271775, 4.7779008380892954e-20, 2.1577602768446062e-15, 1.6711028165942523e-23, 1.0331997425121541e-22, 8.427481583513628e-23, 3.4386599653113344e-30, 3.021645248588356e-31, 8.874706280965021e-29, 1.5970985004815294e-28, 1.7345135629090753e-32, 7.65893158467698e-27, 5.992297704584142e-38, 9.096062460636482e-37, 1.2754058926336668e-33, 1.6477968747050187e-33, 8.866549342447523e-40, 1.470023213396665e-20, 1.282933175584514e-29, 2.2611412650697167e-26]\n",
      "[3.729425623281907e-27, 3.2440544781039293e-07, 3.361472505659429e-28, 2.845626844830449e-28, 1.0, 1.0, 1.2200263874830398e-22, 4.372686341662931e-17, 2.527088877350162e-27, 7.308839231079749e-35, 1.076655578265218e-34, 2.658015192775016e-39, 3.6634648051702356e-36, 2.8656430187598515e-34, 8.866716672739465e-49, 6.322837254993188e-41, 8.875641146769144e-39, 3.913730968113749e-48, 1.4953493810652463e-43, 1.0560328426771588e-51, 4.093252506401054e-54, 8.254551167709833e-59, 1.0753928669696647e-21, 5.178634267101589e-45, 2.448626131263216e-43]\n",
      "[8.790212255483866e-16, 6.696566091237409e-22, 3.212806792428156e-18, 8.884843664427227e-23, 4.809485416215734e-13, 5.327715068600423e-13, 7.44803256002313e-23, 1.3547671965438634e-19, 4.502238342021712e-30, 1.1292960393467716e-14, 1.0148777330406336e-14, 4.709250787315559e-26, 4.156697484195785e-31, 8.538636459211033e-28, 2.20512717080255e-16, 1.3509477631189157e-37, 2.264778282977869e-20, 5.325690299260496e-31, 5.056301221488356e-29, 1.7308894833754353e-28, 7.335151315820732e-22, 9.79311443507619e-31, 3.115864832665233e-25, 4.691075635413521e-19, 0.9999999983192538]\n",
      "0.9999999999999738\n",
      "7.168083216361406e-13\n"
     ]
    }
   ],
   "source": [
    "# Get the book descriptions from the recommendations\n",
    "descriptions = recommendations['Book Description']\n",
    "similardescriptions = recommendations['Similar Description']\n",
    "dissimilardescriptions = recommendations['Dissimilar Description']\n",
    "\n",
    "# Run the vectorizer on the descriptions\n",
    "descriptions = vectorizer.transform(descriptions)\n",
    "similardescriptions = vectorizer.transform(similardescriptions)\n",
    "dissimilardescriptions = vectorizer.transform(dissimilardescriptions)\n",
    "\n",
    "# Create a list of genre scores for each\n",
    "description_scores = []\n",
    "similardescription_scores = []\n",
    "dissimilardescription_scores = []\n",
    "\n",
    "# Get the first set of book descriptions\n",
    "book1 = descriptions[0]\n",
    "book2 = similardescriptions[0]\n",
    "book3 = dissimilardescriptions[0]\n",
    "\n",
    "# Calculate the genre scores for each book\n",
    "for genre in genres:\n",
    "    classifier = classifiers[genre]\n",
    "    # Instead of using the predict method, we use the predict_proba method\n",
    "    # This gives us the probability of the book being in the genre\n",
    "    # We use the probability of the book being in the genre as the score\n",
    "    description_scores.append(classifier.predict_proba(book1)[0][1])\n",
    "    similardescription_scores.append(classifier.predict_proba(book2)[0][1])\n",
    "    dissimilardescription_scores.append(classifier.predict_proba(book3)[0][1])\n",
    "\n",
    "# Print the genre scores for each book\n",
    "print(description_scores)\n",
    "print(similardescription_scores)\n",
    "print(dissimilardescription_scores)\n",
    "\n",
    "# Calculate the cosine similarity between the first book and the second book\n",
    "similarity = cosine_similarity(np.array(description_scores), np.array(similardescription_scores))\n",
    "print(similarity)\n",
    "\n",
    "# Calculate the cosine similarity between the first book and the third book\n",
    "dissimilarity = cosine_similarity(np.array(description_scores), np.array(dissimilardescription_scores))\n",
    "print(dissimilarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to take a row of the recommendations dataframe and calculate the similarity scores\n",
    "def calculate_similarity(row):\n",
    "    # Get the book descriptions\n",
    "    book1 = vectorizer.transform([row['Book Description']])\n",
    "    book2 = vectorizer.transform([row['Similar Description']])\n",
    "    book3 = vectorizer.transform([row['Dissimilar Description']])\n",
    "    # Create a list of genre scores for each\n",
    "    description_scores = []\n",
    "    similardescription_scores = []\n",
    "    dissimilardescription_scores = []\n",
    "    # Calculate the genre scores for each book\n",
    "    for genre in genres:\n",
    "        classifier = classifiers[genre]\n",
    "        description_scores.append(classifier.predict_proba(book1)[0][1])\n",
    "        similardescription_scores.append(classifier.predict_proba(book2)[0][1])\n",
    "        dissimilardescription_scores.append(classifier.predict_proba(book3)[0][1])\n",
    "    # Calculate the cosine similarity between the first book and the second book\n",
    "    similarity = cosine_similarity(description_scores, similardescription_scores)\n",
    "    # Calculate the cosine similarity between the first book and the third book\n",
    "    dissimilarity = cosine_similarity(description_scores, dissimilardescription_scores)\n",
    "    return similarity, dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Similarity  Dissimilarity\n",
      "0    1.000000   7.168083e-13\n",
      "1    0.774487   2.367824e-06\n",
      "2    1.000000   3.468775e-06\n",
      "3    0.831147   9.500289e-02\n",
      "4    0.994236   1.578341e-08\n"
     ]
    }
   ],
   "source": [
    "# Create a new dataframe to store the similarity scores for each row\n",
    "similarity_scores = pd.DataFrame(columns=['Similarity', 'Dissimilarity'])\n",
    "\n",
    "# Calculate the similarity scores for each row\n",
    "for index, row in recommendations.iterrows():\n",
    "    #print(index)\n",
    "    similarity, dissimilarity = calculate_similarity(row)\n",
    "    similarity_scores.loc[index] = [similarity, dissimilarity]\n",
    "\n",
    "# Print the similarity scores\n",
    "print(similarity_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Similarity  Dissimilarity\n",
      "0    1.000000   7.168083e-13\n",
      "1    0.774487   2.367824e-06\n",
      "2    1.000000   3.468775e-06\n",
      "3    0.831147   9.500289e-02\n",
      "4    0.994236   1.578341e-08\n"
     ]
    }
   ],
   "source": [
    "print(similarity_scores.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of correct predictions\n",
      "0.9260812581913499\n",
      "Percentage of similarity score greater than 0.5\n",
      "0.7491480996068152\n",
      "Percentage of dissimilarity score less than 0.5\n",
      "0.9425950196592399\n"
     ]
    }
   ],
   "source": [
    "# Calculate the percentage of correct predictions\n",
    "correct = (similarity_scores['Similarity'] > similarity_scores['Dissimilarity']).mean()\n",
    "print(\"Percentage of correct predictions\")\n",
    "print(correct)\n",
    "\n",
    "# Count the percentage of times the similarity score is greater than 0.5\n",
    "similar_correct = (similarity_scores['Similarity'] > 0.5).mean()\n",
    "print(\"Percentage of similarity score greater than 0.5\")\n",
    "print(similar_correct)\n",
    "\n",
    "# Count the percentage of times the dissimilarity score is less than 0.5\n",
    "dissimilar_correct = (similarity_scores['Dissimilarity'] < 0.5).mean()\n",
    "print(\"Percentage of dissimilarity score less than 0.5\")\n",
    "print(dissimilar_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3533\n",
      "957\n",
      "219\n",
      "Accuracy: 0.9260812581913499\n",
      "Precision: 0.7868596881959911\n",
      "Recall: 0.9416311300639659\n",
      "F1 Score: 0.8573161853918951\n"
     ]
    }
   ],
   "source": [
    "# Calculate the precision, recall, and F1 score of the similarity scores\n",
    "true_positives = sum(similarity_scores['Similarity'] > similarity_scores['Dissimilarity'])\n",
    "print(true_positives)\n",
    "false_positives = sum(similarity_scores['Similarity'] < 0.5)\n",
    "print(false_positives)\n",
    "false_negatives = sum(similarity_scores['Dissimilarity'] > 0.5)\n",
    "print(false_negatives)\n",
    "\n",
    "accuracy = correct\n",
    "precision = true_positives / (true_positives + false_positives)\n",
    "recall = true_positives / (true_positives + false_negatives)\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "# Save the accuracy, precision, recall, and F1 score to a file\n",
    "with open('NBresults.txt', 'w') as f:\n",
    "    f.write('Accuracy: ' + str(accuracy) + '\\n')\n",
    "    f.write('Precision: ' + str(precision) + '\\n')\n",
    "    f.write('Recall: ' + str(recall) + '\\n')\n",
    "    f.write('F1 Score: ' + str(f1) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
